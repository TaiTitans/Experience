# Working with Parallel Streams

We conclude this chapter by combining what you learned in Chapter 10, “Streams,” with the
concepts you learned about in this chapter. One of the most powerful features of the Stream
API is built-in concurrency support. Up until now, all of the streams you have worked with
have been serial streams. A _serial stream_ is a stream in which the results are ordered, with
only one entry being processed at a time. <br />

&emsp;&emsp;
A _parallel stream_ is capable of processing results concurrently, using multiple threads. For
example, you can use a parallel stream and the `map()` operation to operate concurrently on
the elements in the stream, vastly improving performance over processing a single element
at a time. <br />

&emsp;&emsp;
Using a parallel stream can change not only the performance of your application but also
the expected results. As you shall see, some operations also require special handling to be
able to be processed in a parallel manner.

> #### Tip
> The number of threads available in a parallel stream is proportional to the
number of available CPUs in your environment.

## I. Creating Parallel Streams
The Stream API was designed to make creating parallel streams quite easy. For the exam,
you should be familiar with two ways of creating a parallel stream.

```java
Collection<Integer> collection = List.of(1,2);

Stream<Integer> p1 = collection.stream().parallel();
Stream<Integer> p2 = collection.parallelStream();
```

&emsp;&emsp;
The first way to create a parallel stream is from an existing stream. Isn’t this cool? Any
stream can be made parallel! The second way to create a parallel stream is from a Java
**Collection** class. We use both of these methods throughout this section.

> #### Note
> The **Stream** interface includes a method `isParallel()` that can be used
to test whether the instance of a stream supports parallel processing.
Some operations on streams preserve the parallel attribute, while others
do not.

## II. Performing a Parallel Decomposition
A _parallel decomposition_ is the process of taking a task, breaking it into smaller pieces that
can be performed concurrently, and then reassembling the results. The more concurrent a
decomposition, the greater the performance improvement of using parallel streams. <br />

&emsp;&emsp;
Let’s try it out. First, let’s define a reusable function that “does work” just by waiting for
five seconds.

```java
private static int doWork(int input) {
    try {
        Thread.sleep(5000);
    } catch (InterruptedException e) {}
    return input;
}
```

&emsp;&emsp;
We can pretend that in a real application, this work might involve calling a database or
reading a file. Now let’s use this method with a serial stream.

```
10: long start = System.currentTimeMillis();
11: List.of(1,2,3,4,5)
12:     .stream()
13:     .map(w -> doWork(w))
14:     .forEach(s -> System.out.print(s + " "));
15:
16: System.out.println();
17: var timeTaken = (System.currentTimeMillis() - start) / 1000;
18: System.out.println("Time: " + timeTaken + " seconds");
```

&emsp;&emsp;
What do you think this code will output when executed as part of a `main()` method?
Let’s take a look:

```
1 2 3 4 5
Time: 25 seconds
```

&emsp;&emsp;
As you might expect, the results are ordered and predictable because we are using a serial
stream. It also took around 25 seconds to process all five results, one at a time. What happens 
if we replace line 12 with one that uses a `parallelStream()`? The following is some
sample output:

```
3 2 1 5 4
Time: 5 seconds
```

&emsp;&emsp;
As you can see, the results are no longer ordered or predictable. The `map()` and
`forEach()` operations on a parallel stream are equivalent to submitting multiple **Runnable**
lambda expressions to a pooled thread executor and then waiting for the results. <br />

&emsp;&emsp;
What about the time required? In this case, our system had enough CPUs for all of the
tasks to be run concurrently. If you ran this same code on a computer with fewer processors, it might output 10 seconds, 15 seconds, or some other value. The key is that
we’ve written our code to take advantage of parallel processing when available, so our
job is done.

> #### Ordering Results
> If your stream operation needs to guarantee ordering and you’re not sure if it is serial or
parallel, you can replace line 14 with one that uses `forEachOrdered()`:
> ```
> 14: .forEachOrdered(s -> System.out.print(s + " "));
> ```
> This outputs the results in the order in which they are defined in the stream:
> ```
> 1 2 3 4 5
> Time: 5 seconds
> ```
> While we’ve lost some of the performance gains of using a parallel stream, our `map()` 
operation can still take advantage of the parallel stream.

## III. Processing Parallel Reductions
Besides potentially improving performance and modifying the order of operations, using
parallel streams can impact how you write your application. A _parallel reduction_ is a
reduction operation applied to a parallel stream. The results for parallel reductions can differ
from what you expect when working with serial streams.

### &emsp;&emsp; 1. Performing Order-Based Tasks
Since order is not guaranteed with parallel streams, methods such as `findAny()` on parallel
streams may result in unexpected behavior. Consider the following example:

```java
System.out.print(List.of(1,2,3,4,5,6)
    .parallelStream()
    .findAny()
    .get());
```

&emsp;&emsp;
The JVM allocates a number of threads and returns the value of the first one to return
a result, which could be 4, 2, and so on. While _neither_ the serial nor the parallel stream is
guaranteed to return the first value, the serial stream often does. With a parallel stream, the
results are likely to be more random. <br />

&emsp;&emsp;
What about operations that consider order, such as `findFirst()`, `limit()`, and `skip()`? Order
is still preserved, but performance may **suffer** on a parallel stream as a result of a parallel
processing task being forced to coordinate all of its threads in a synchronized-like fashion. <br />

&emsp;&emsp;
On the plus side, the results of ordered operations on a parallel stream will be consistent
with a serial stream. For example, calling `skip(5).limit(2).findFirst()` will return
the same result on ordered serial and parallel streams.

> ### Real World Scenario
> #### Creating Unordered Streams
> All of the streams you have been working with are considered ordered by default. It is 
possible to create an unordered stream from an ordered stream, similar to how you create a
parallel stream from a serial stream.
> ```
> List.of(1,2,3,4,5,6).stream().unordered();
> ```
> This method does not reorder the elements; it just tells the JVM that if an order-based stream
operation is applied, the order can be ignored. For example, calling `skip(5)` on an unordered
stream will skip any 5 elements, not necessarily the first 5 required on an ordered stream.
>
> For serial streams, using an unordered version has no effect. But on parallel streams, the
results can greatly improve performance.
> ```
> List.of(1,2,3,4,5,6).stream().unordered().parallel();
> ```
> Even though unordered streams will not be on the exam, if you are developing applications
with parallel streams, you should know when to apply an unordered stream to improve
performance.

### &emsp;&emsp; 2. Combining Results with `reduce()`
As you learned in Chapter 10, the stream operation `reduce()` combines a stream into a
single object. Recall that the first parameter to the `reduce()` method is called the _identity_,
the second parameter is called the _accumulator_, and the third parameter is called the
_combiner_. The following is the signature for the method:

```java
<U> U reduce(U identity,
    BiFunction<U,? super T,U> accumulator,
    BinaryOperator<U> combiner)
```

&emsp;&emsp;
We can concatenate a list of char values using the `reduce()` method, as shown in the
following example:

```java
System.out.println(List.of('w', 'o', 'l', 'f')
    .parallelStream()
    .reduce("",
        (s1,c) -> s1 + c,
        (s2,s3) -> s2 + s3)); // wolf
```

> #### Note
> The naming of the variables in this stream example is not accidental. We
used c for char, whereas s1, s2, and s3 are String values.

&emsp;&emsp;
On parallel streams, the `reduce()` method works by applying the reduction to pairs
of elements within the stream to create intermediate values and then combining those
intermediate values to produce a final result. Put another way, in a serial stream, wolf is
built one character at a time. In a parallel stream, the intermediate values **wo** and **lf** are 
created and then combined. <br />

&emsp;&emsp;
With parallel streams, we now have to be concerned about order. What if the elements of
a string are combined in the wrong order to produce **wlfo** or **flwo**? The Stream API prevents
this problem while still allowing streams to be processed in parallel, as long as you follow
one simple rule: make sure that the accumulator and combiner produce the same result
regardless of the order they are called in.

> #### Note
> While this is not in scope for the exam, the accumulator and combiner
must be associative, non-interfering, and stateless. Don’t panic; you don’t
need to know advanced math terms for the exam!

&emsp;&emsp;
While the requirements for the input arguments to the `reduce()` method hold true for
both serial and parallel streams, you may not have noticed any problems in serial streams
because the result was always ordered. With parallel streams, though, order is no longer
guaranteed, and any argument that violates these rules is much more likely to produce side
effects or unpredictable results. <br />

&emsp;&emsp;
Let’s take a look at an example using a problematic accumulator. In particular, order matters 
when subtracting numbers; therefore, the following code can output different values
depending on whether you use a serial or parallel stream. We can omit a combiner parameter 
in these examples, as the accumulator can be used when the intermediate data types
are the same.

```java
System.out.println(List.of(1,2,3,4,5,6)
    .parallelStream()
    .reduce(0, (a, b) -> (a - b))); // PROBLEMATIC ACCUMULATOR
```

&emsp;&emsp;
It may output **-21**, **3**, or some other value. <br />

&emsp;&emsp;
You can see other problems if we use an identity parameter that is not truly an identity
value. For example, what do you expect the following code to output?

```java
System.out.println(List.of("w","o","l","f")
    .parallelStream()
    .reduce("X", String::concat)); // XwXoXlXf
```

&emsp;&emsp;
On a serial stream, it prints **Xwolf**, but on a parallel stream, the result is **XwXoXlXf**. As
part of the parallel process, the identity is applied to multiple elements in the stream, 
resulting in very unexpected data.

> #### Selecting a _reduce()_ Method
> Although the one- and two-argument versions of `reduce()` support parallel processing, it
is recommended that you use the three-argument version of `reduce()` when working with
parallel streams. Providing an explicit combiner method allows the JVM to partition the
operations in the stream more efficiently.

### &emsp;&emsp; 3. Combining Results with `collect()`
Like `reduce()`, the Stream API includes a three-argument version of `collect()` that takes
_accumulator_ and _combiner_ operators along with a supplier operator instead of an identity.

```java
<R> R collect(Supplier<R> supplier,
    BiConsumer<R, ? super T> accumulator,
    BiConsumer<R, R> combiner)
```

&emsp;&emsp;
Also, like `reduce()`, the accumulator and combiner operations must be able to process
results in any order. In this manner, the three-argument version of `collect()` can be 
performed as a parallel reduction, as shown in the following example:

```java
Stream<String> stream = Stream.of("w", "o", "l", "f").parallel();
SortedSet<String> set = stream.collect(ConcurrentSkipListSet::new,
    Set::add,
    Set::addAll);
System.out.println(set); // [f, l, o, w]
```

&emsp;&emsp;
Recall that elements in a **ConcurrentSkipListSet** are sorted according to their natural
ordering. You should use a concurrent collection to combine the results, ensuring that the
results of concurrent threads do not cause a **ConcurrentModificationException**. <br />

&emsp;&emsp;
Performing parallel reductions with a collector requires additional considerations. For
example, if the collection into which you are inserting is an ordered data set, such as a List,
the elements in the resulting collection must be in the same order, regardless of whether you
use a serial or parallel stream. This may reduce performance, though, as some operations
cannot be completed in parallel.

### &emsp;&emsp; 4. Performing a Parallel Reduction on a Collector
While we covered the **Collector** interface in Chapter 10, we didn’t go into detail about its
properties. Every **Collector** instance defines a `characteristics()` method that returns
a set of **Collector.Characteristics** attributes. When using a **Collector** to perform a
parallel reduction, a number of properties must hold true. Otherwise, the `collect()` 
operation will execute in a single-threaded fashion. <br />

**Requirements for Parallel Reduction with _collect()_**
- The stream is parallel.
- The parameter of the `collect()` operation has the **Characteristics.CONCURRENT** characteristic.
- Either the stream is unordered or the collector has the characteristic **Characteristics.UNORDERED**.

&emsp;&emsp;
For example, while `Collectors.toSet()` does have the **UNORDERED** characteristic,
it does not have the **CONCURRENT** characteristic. Therefore, the following is not a parallel
reduction even with a parallel stream:

```java
parallelStream.collect(Collectors.toSet()); // Not a parallel reduction
```

&emsp;&emsp;
The **Collectors** class includes two sets of **static** methods for retrieving collectors,
`toConcurrentMap()` and `groupingByConcurrent()`, both of which are **UNORDERED** and
**CONCURRENT**. These methods produce **Collector** instances capable of performing parallel
reductions efficiently. Like their nonconcurrent counterparts, there are overloaded versions
that take additional arguments. <br />

&emsp;&emsp;
Here is a rewrite of an example from Chapter 10 to use a parallel stream and parallel
reduction:

```java
Stream<String> ohMy = Stream.of("lions", "tigers", "bears").parallel();
ConcurrentMap<Integer, String> map = ohMy
    .collect(Collectors.toConcurrentMap(String::length,
        k -> k,
        (s1, s2) -> s1 + "," + s2));
System.out.println(map);            // {5=lions,bears, 6=tigers}
System.out.println(map.getClass()); // java.util.concurrent.ConcurrentHashMap
```

&emsp;&emsp;
We use a **ConcurrentMap** reference, although the actual class returned is likely
**ConcurrentHashMap**. The particular class is not guaranteed; it will just be a class that
implements the interface **ConcurrentMap**. <br />

&emsp;&emsp;
Finally, we can rewrite our `groupingBy()` example from Chapter 10 to use a parallel stream
and parallel reduction.

```java
var ohMy = Stream.of("lions", "tigers", "bears").parallel();
ConcurrentMap<Integer, List<String>> map = ohMy.collect(
    Collectors.groupingByConcurrent(String::length));
System.out.println(map);        // {5=[lions, bears], 6=[tigers]}
```

&emsp;&emsp;
As before, the returned object can be assigned to a **ConcurrentMap** reference.

> ### Real World Scenario
> #### Avoiding Stateful Streams
> Side effects can appear in parallel streams if your lambda expressions are stateful. A 
_stateful lambda expression_ is one whose result depends on any state that might change during
the execution of a pipeline. For example, the following method that filters out even 
numbers is stateful:
> ```
>   public List<Integer> addValues(IntStream source) {
>       var data = Collections.synchronizedList(new ArrayList<Integer>());
>       source.filter(s -> s % 2 == 0)
>           .forEach(i -> { data.add(i); }); // STATEFUL: DON'T DO THIS!
>       return data;
>   }
> ```
> Let’s say this method is executed with a serial stream:
> ```
> var list = addValues(IntStream.range(1, 11));
> System.out.print(list);       // [2, 4, 6, 8, 10]
> ```
> Great, the results are in the same order that they were entered. But what if someone else
passes in a parallel stream?
> ```
> var list = addValues(IntStream.range(1, 11).parallel());
> System.out.print(list);       // [6, 8, 10, 2, 4]
> ```
> Oh, no: our results no longer match our input order! The problem is that our lambda
expression is stateful and modifies a list that is outside our stream. We can fix this solution
by rewriting our stream operation to be stateless:
> ```
>   public List<Integer> addValuesBetter(IntStream source) {
>       return source.filter(s -> s % 2 == 0)
>           .boxed()
>           .collect(Collectors.toList());
>   }
> ```
> This method processes the stream and then collects all the results into a new list. It 
produces the same ordered result on both serial and parallel streams. It is strongly 
recommended that you avoid stateful operations when using parallel streams, to remove any
potential data side effects. In fact, they should be avoided in serial streams since doing so
limits the code’s ability to someday take advantage of parallelization.
